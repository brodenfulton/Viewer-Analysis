import mediapipe as mp
import cv2
import numpy as np
from collections import deque
import math
import json
import csv
from datetime import datetime
import os
import time

class ViewerAnalysis:
    def __init__(self):
        self.mp_pose = mp.solutions.pose
        
        self.cap = cv2.VideoCapture(0)
        if not self.cap.isOpened():
            raise ValueError("Could not open camera")
        
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        
        self.mp_face_mesh = mp.solutions.face_mesh
        self.face_mesh = self.mp_face_mesh.FaceMesh(
            max_num_faces=1,
            refine_landmarks=True,
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )

        self.pose = self.mp_pose.Pose(
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )

        # Add tracking variables
        self.prev_body_landmarks = None
        self.body_movement_history = deque(maxlen=30)
        self.arm_angles_history = deque(maxlen=30)

        # Add landmarks
        self.UPPER_BODY_LANDMARKS = [
            self.mp_pose.PoseLandmark.LEFT_SHOULDER,
            self.mp_pose.PoseLandmark.RIGHT_SHOULDER,
            self.mp_pose.PoseLandmark.LEFT_ELBOW,
            self.mp_pose.PoseLandmark.RIGHT_ELBOW,
            self.mp_pose.PoseLandmark.LEFT_WRIST,
            self.mp_pose.PoseLandmark.RIGHT_WRIST,
            self.mp_pose.PoseLandmark.NOSE,
            self.mp_pose.PoseLandmark.LEFT_EAR,
            self.mp_pose.PoseLandmark.RIGHT_EAR
        ]
        
        # Tracking variables
        self.prev_landmarks = None
        self.movement_history = deque(maxlen=30)
        self.eye_aspect_ratios = deque(maxlen=30)
        self.mouth_aspect_ratios = deque(maxlen=30)
        self.eye_movement_history = deque(maxlen=30)  
        
        # Blink Detection
        self.blink_timestamps = deque(maxlen=300)
        self.was_eye_closed = False
        self.blink_rate = 0
        self.MIN_BLINK_INTERVAL = 0.1
        self.last_blink_time = time.time()
        self.EYE_AR_THRESH = 0.21
        self.EYE_AR_CONSEC_FRAMES = 2
        self.eye_counter = 0
        self.total_blinks = 0
        
        # Eye tracking
        self.IRIS_LANDMARKS = {
            'left_iris': [468, 469, 470, 471, 472],
            'right_iris': [473, 474, 475, 476, 477]
        }
        
        # Reference eye points for calculations
        self.eye_refs = {
            'left': {'left': 33, 'right': 133, 'top': 159, 'bottom': 145},
            'right': {'left': 362, 'right': 263, 'top': 386, 'bottom': 374}
        }
        
        # Timing for data logging
        self.last_log_time = time.time()
        self.LOG_INTERVAL = 2.0
        
        # Facial features
        self.FACIAL_FEATURES = {
            'left_eye': [
                33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157,
                158, 159, 160, 161, 246,
                46, 53, 52, 65, 55
            ],
            'right_eye': [
                362, 382, 381, 380, 374, 373, 390, 249, 263, 466,
                388, 387, 386, 385, 384, 398,
                276, 283, 282, 295, 285
            ],
            'mouth': [
                61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291,
                62, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415,
                76, 77, 90, 180, 85, 16, 315, 404, 320, 307,
                402, 317, 14, 87, 178, 88, 95,
                185, 40, 39, 37, 0, 267, 269, 270, 409
            ],
            'face_outline': [
                10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288,
                397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136,
                172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109
            ]
        }
        
        self.csv_headers = [
            'timestamp', 
            'eye_openness',
            'blink_rate', 
            'mouth_openness',
            'mouth_movement',
            'head_movement',
            'eye_movement_x',  
            'eye_movement_y',
            'shoulder_movement',
            'arm_movement', 
            'upper_body_rotation',
            'left_arm_angle',
            'right_arm_angle'
        ]
        self.setup_logging()

    def calculate_eye_movement(self, face_landmarks, w, h):
        """Calculate eye movement relative to eye corners"""
        movements = {'left': {'x': 0, 'y': 0}, 'right': {'x': 0, 'y': 0}}
        
        try:
            for eye in ['left', 'right']:
                # Iris center
                iris_idx = self.IRIS_LANDMARKS[f'{eye}_iris'][0]
                iris = face_landmarks.landmark[iris_idx]
                iris_x, iris_y = iris.x * w, iris.y * h
                
                # Eye corners
                refs = self.eye_refs[eye]
                left_corner = face_landmarks.landmark[refs['left']]
                right_corner = face_landmarks.landmark[refs['right']]
                top_point = face_landmarks.landmark[refs['top']]
                bottom_point = face_landmarks.landmark[refs['bottom']]

                left_x, left_y = left_corner.x * w, left_corner.y * h
                right_x, right_y = right_corner.x * w, right_corner.y * h
                top_x, top_y = top_point.x * w, top_point.y * h
                bottom_x, bottom_y = bottom_point.x * w, bottom_point.y * h
                
                # Calculate eye width and height
                eye_width = right_x - left_x
                eye_height = bottom_y - top_y
                
                # Calculate relative position of iris (-1 to 1 range)
                x_rel = 2 * (iris_x - left_x) / eye_width - 1
                y_rel = 2 * (iris_y - top_y) / eye_height - 1
                
                movements[eye] = {'x': x_rel, 'y': y_rel}
        
        except Exception as e:
            print(f"Error calculating eye movement: {e}")
        
        return movements

    def calculate_body_metrics(self, pose_landmarks, w, h):
        """Calculate upper body movement metrics"""
        metrics = {
            'shoulder_movement': 0,
            'arm_movement': 0,
            'upper_body_rotation': 0,
            'left_arm_angle': 0,
            'right_arm_angle': 0
        }
        
        if not pose_landmarks:
            return metrics
            
        try:
            # Get current landmark positions
            current_landmarks = []
            for landmark in self.UPPER_BODY_LANDMARKS:
                point = pose_landmarks.landmark[landmark]
                px, py = int(point.x * w), int(point.y * h)
                current_landmarks.append((px, py))
            
            # Calculate shoulder movement
            if self.prev_body_landmarks:
                shoulder_movement = sum(self.distance(p1, p2) 
                    for p1, p2 in zip(current_landmarks[:2], self.prev_body_landmarks[:2]))
                metrics['shoulder_movement'] = shoulder_movement
                
                # Calculate overall arm movement
                arm_points = current_landmarks[2:6]  # elbows and wrists
                prev_arm_points = self.prev_body_landmarks[2:6]
                arm_movement = sum(self.distance(p1, p2) 
                    for p1, p2 in zip(arm_points, prev_arm_points))
                metrics['arm_movement'] = arm_movement
            
            # Calculate upper body rotation using nose and ears
            nose = pose_landmarks.landmark[self.mp_pose.PoseLandmark.NOSE]
            left_ear = pose_landmarks.landmark[self.mp_pose.PoseLandmark.LEFT_EAR]
            right_ear = pose_landmarks.landmark[self.mp_pose.PoseLandmark.RIGHT_EAR]
            
            ear_distance = abs((left_ear.x - right_ear.x) * w)
            if ear_distance > 0:
                rotation = abs((nose.x - (left_ear.x + right_ear.x)/2) * w / ear_distance)
                metrics['upper_body_rotation'] = rotation
            
            # Calculate arm angles
            def calculate_arm_angle(shoulder, elbow, wrist):
                vector1 = [elbow.x - shoulder.x, elbow.y - shoulder.y]
                vector2 = [wrist.x - elbow.x, wrist.y - elbow.y]
                dot_product = vector1[0] * vector2[0] + vector1[1] * vector2[1]
                magnitudes = math.sqrt(vector1[0]**2 + vector1[1]**2) * math.sqrt(vector2[0]**2 + vector2[1]**2)
                if magnitudes == 0:
                    return 0
                angle = math.acos(max(min(dot_product / magnitudes, 1), -1))
                return math.degrees(angle)
            
            # Left arm angle
            left_shoulder = pose_landmarks.landmark[self.mp_pose.PoseLandmark.LEFT_SHOULDER]
            left_elbow = pose_landmarks.landmark[self.mp_pose.PoseLandmark.LEFT_ELBOW]
            left_wrist = pose_landmarks.landmark[self.mp_pose.PoseLandmark.LEFT_WRIST]
            metrics['left_arm_angle'] = calculate_arm_angle(left_shoulder, left_elbow, left_wrist)
            
            # Right arm angle
            right_shoulder = pose_landmarks.landmark[self.mp_pose.PoseLandmark.RIGHT_SHOULDER]
            right_elbow = pose_landmarks.landmark[self.mp_pose.PoseLandmark.RIGHT_ELBOW]
            right_wrist = pose_landmarks.landmark[self.mp_pose.PoseLandmark.RIGHT_WRIST]
            metrics['right_arm_angle'] = calculate_arm_angle(right_shoulder, right_elbow, right_wrist)
            
            self.prev_body_landmarks = current_landmarks
            self.body_movement_history.append(metrics)
            
        except Exception as e:
            print(f"Error calculating body metrics: {e}")
        
        return metrics

    def calculate_eye_aspect_ratio(self, eye_points):
        """Calculate eye aspect ratio"""
        # Vertical distances
        v1 = self.distance(eye_points[1], eye_points[7])
        v2 = self.distance(eye_points[2], eye_points[6])
        
        # Horizontal distance
        h = self.distance(eye_points[0], eye_points[4])
        
        # Calculate EAR
        ear = (v1 + v2) / (2.0 * h + 1e-6)
        return ear

    def detect_blink(self, ear):
        """Enhanced blink detection using eye aspect ratio (EAR) and consecutive frames"""
        current_time = time.time()
        
        if ear < self.EYE_AR_THRESH:
            self.eye_counter += 1
        else:
            # If eyes were closed for sufficient frames, count as blink
            if self.eye_counter >= self.EYE_AR_CONSEC_FRAMES:
                if current_time - self.last_blink_time >= self.MIN_BLINK_INTERVAL:
                    self.total_blinks += 1
                    self.blink_timestamps.append(current_time)
                    self.last_blink_time = current_time
                    self.update_blink_rate()
            
            # Reset counter
            self.eye_counter = 0

    def update_blink_rate(self):
        current_time = time.time()
        while self.blink_timestamps and (current_time - self.blink_timestamps[0]) > 60:
            self.blink_timestamps.popleft()
        self.blink_rate = len(self.blink_timestamps)

    def setup_logging(self):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.log_dir = f"viewer_analysis_logs_{timestamp}"
        os.makedirs(self.log_dir, exist_ok=True)
        
        self.csv_path = os.path.join(self.log_dir, "viewer_metrics.csv")
        with open(self.csv_path, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(self.csv_headers)
        
        self.json_path = os.path.join(self.log_dir, "detailed_metrics.json")
        self.json_log = []

    def process_frame(self, show=True):
        ret, frame = self.cap.read()
        if not ret or frame is None:
            return None
            
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        face_results = self.face_mesh.process(frame_rgb)
        pose_results = self.pose.process(frame_rgb)

        annotated_frame = frame.copy()
        h, w, _ = frame.shape
        
        if face_results.multi_face_landmarks:
            face_landmarks = face_results.multi_face_landmarks[0]
         
            # Update tracking data
            current_landmarks = []
            for landmark in face_landmarks.landmark:
                px = int(landmark.x * w)
                py = int(landmark.y * h)
                current_landmarks.append((px, py))
            
            if self.prev_landmarks is not None:
                movement = sum(self.distance(p1, p2) 
                             for p1, p2 in zip(current_landmarks, self.prev_landmarks))
                self.movement_history.append(movement)
            
            self.prev_landmarks = current_landmarks
            
            # Calculate eye movements
            eye_movements = self.calculate_eye_movement(face_landmarks, w, h)
            self.eye_movement_history.append(eye_movements)
            
            # Calculate average eye movement
            avg_movement = {'x': 0, 'y': 0}
            if self.eye_movement_history:
                for movement in self.eye_movement_history:
                    avg_movement['x'] += (movement['left']['x'] + movement['right']['x']) / 2
                    avg_movement['y'] += (movement['left']['y'] + movement['right']['y']) / 2
                avg_movement['x'] /= len(self.eye_movement_history)
                avg_movement['y'] /= len(self.eye_movement_history)
            
            # Calculate EAR for both eyes
            left_eye_points = [(int(face_landmarks.landmark[idx].x * w),
                              int(face_landmarks.landmark[idx].y * h))
                             for idx in self.FACIAL_FEATURES['left_eye'][:8]]
            
            right_eye_points = [(int(face_landmarks.landmark[idx].x * w),
                               int(face_landmarks.landmark[idx].y * h))
                              for idx in self.FACIAL_FEATURES['right_eye'][:8]]
            
            left_ear = self.calculate_eye_aspect_ratio(left_eye_points)
            right_ear = self.calculate_eye_aspect_ratio(right_eye_points)
            ear = (left_ear + right_ear) / 2.0
            self.eye_aspect_ratios.append(ear)
            
            self.detect_blink(ear)
            
            # Draw facial features
            for feature_name, indices in self.FACIAL_FEATURES.items():
                points = []
                for idx in indices:
                    point = face_landmarks.landmark[idx]
                    px, py = int(point.x * w), int(point.y * h)
                    points.append((px, py))
                    cv2.circle(annotated_frame, (px, py), 1, (0, 255, 0), -1)
                
                for i in range(len(points) - 1):
                    cv2.line(annotated_frame, points[i], points[i + 1], (0, 255, 0), 1)
            
            # Draw iris tracking points
            for eye_name, landmarks in self.IRIS_LANDMARKS.items():
                for idx in landmarks:
                    point = face_landmarks.landmark[idx]
                    px, py = int(point.x * w), int(point.y * h)
                    cv2.circle(annotated_frame, (px, py), 2, (255, 0, 0), -1)
            
            # Enhanced visualization including eye movement
            cv2.putText(annotated_frame, f'EAR: {ear:.2f}', (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(annotated_frame, f'Blinks: {self.total_blinks}', (10, 60),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(annotated_frame, f'Blink Rate: {self.blink_rate} blinks/min', (10, 90),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(annotated_frame, f'Eye Move X: {avg_movement["x"]:.2f}', (10, 120),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(annotated_frame, f'Eye Move Y: {avg_movement["y"]:.2f}', (10, 150),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            if pose_results.pose_landmarks:
                body_metrics = self.calculate_body_metrics(pose_results.pose_landmarks, w, h)
                
                # Draw upper body landmarks and connections
                for landmark in self.UPPER_BODY_LANDMARKS:
                    point = pose_results.pose_landmarks.landmark[landmark]
                    px, py = int(point.x * w), int(point.y * h)
                    cv2.circle(annotated_frame, (px, py), 3, (0, 0, 255), -1)
                
                # Draw connections between landmarks
                connections = [
                    (self.mp_pose.PoseLandmark.LEFT_SHOULDER, self.mp_pose.PoseLandmark.RIGHT_SHOULDER),
                    (self.mp_pose.PoseLandmark.LEFT_SHOULDER, self.mp_pose.PoseLandmark.LEFT_ELBOW),
                    (self.mp_pose.PoseLandmark.LEFT_ELBOW, self.mp_pose.PoseLandmark.LEFT_WRIST),
                    (self.mp_pose.PoseLandmark.RIGHT_SHOULDER, self.mp_pose.PoseLandmark.RIGHT_ELBOW),
                    (self.mp_pose.PoseLandmark.RIGHT_ELBOW, self.mp_pose.PoseLandmark.RIGHT_WRIST)
                ]
                
                for connection in connections:
                    start_point = pose_results.pose_landmarks.landmark[connection[0]]
                    end_point = pose_results.pose_landmarks.landmark[connection[1]]
                    cv2.line(annotated_frame, 
                            (int(start_point.x * w), int(start_point.y * h)),
                            (int(end_point.x * w), int(end_point.y * h)),
                            (0, 0, 255), 2)
                
                # Add body metrics visualization
                cv2.putText(annotated_frame, f'Shoulder Move: {body_metrics["shoulder_movement"]:.2f}',
                           (10, 180), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                cv2.putText(annotated_frame, f'Arm Move: {body_metrics["arm_movement"]:.2f}',
                           (10, 210), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                cv2.putText(annotated_frame, f'Body Rotation: {body_metrics["upper_body_rotation"]:.2f}',
                           (10, 240), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            if self.should_log_data():
                frame_data = self.analyze_metrics(face_landmarks, w, h)
                frame_data['eye_movement_x'] = avg_movement['x']
                frame_data['eye_movement_y'] = avg_movement['y']
                if pose_results.pose_landmarks:
                    frame_data.update(body_metrics)
                self.log_data(frame_data)
        
        if show:
            cv2.imshow('Facial and Body Analysis', annotated_frame)
            
        return annotated_frame

    def analyze_metrics(self, face_landmarks, w, h):
        frame_data = {}
        
        try:
            # Calculate mouth measurements
            mouth_points = [(int(face_landmarks.landmark[idx].x * w),
                           int(face_landmarks.landmark[idx].y * h))
                          for idx in self.FACIAL_FEATURES['mouth'][:20]]
            
            mouth_height = self.distance(mouth_points[2], mouth_points[8])
            mouth_width = self.distance(mouth_points[0], mouth_points[6])
            mar = mouth_width / (mouth_height + 1e-6)
            self.mouth_aspect_ratios.append(mar)
            
            frame_data = {
                'eye_openness': np.mean(self.eye_aspect_ratios) if self.eye_aspect_ratios else 0,
                'mouth_openness': mar,
                'movement': np.mean(self.movement_history) if self.movement_history else 0
            }
            
        except Exception as e:
            print(f"Error in metrics analysis: {e}")
            frame_data = {'error': str(e)}
        
        return frame_data

    def distance(self, p1, p2):
        return math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)

    def should_log_data(self):
        current_time = time.time()
        if current_time - self.last_log_time >= self.LOG_INTERVAL:
            self.last_log_time = current_time
            return True
        return False

    def log_data(self, frame_data):
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        mouth_movement = 0
        if len(self.mouth_aspect_ratios) >= 2:
            mouth_movement = abs(self.mouth_aspect_ratios[-1] - self.mouth_aspect_ratios[-2])
        
        csv_row = [
            timestamp,
            frame_data['eye_openness'],
            self.blink_rate,
            frame_data['mouth_openness'],
            mouth_movement,
            frame_data['movement'],
            frame_data.get('eye_movement_x', 0), 
            frame_data.get('eye_movement_y', 0),
            frame_data.get('shoulder_movement', 0),
            frame_data.get('arm_movement', 0),
            frame_data.get('upper_body_rotation', 0),
            frame_data.get('left_arm_angle', 0),
            frame_data.get('right_arm_angle', 0)
        ]
        
        with open(self.csv_path, 'a', newline='') as f:
            writer = csv.writer(f)
            writer.writerow(csv_row)
        
        json_data = {
            'timestamp': timestamp,
            'metrics': {
                'eye_openness': frame_data['eye_openness'],
                'blink_rate': self.blink_rate,
                'mouth_openness': frame_data['mouth_openness'],
                'mouth_movement': mouth_movement,
                'head_movement': frame_data['movement'],
                'eye_movement_x': frame_data.get('eye_movement_x', 0),
                'eye_movement_y': frame_data.get('eye_movement_y', 0),
                'shoulder_movement': frame_data.get('shoulder_movement', 0),
                'arm_movement': frame_data.get('arm_movement', 0),
                'upper_body_rotation': frame_data.get('upper_body_rotation', 0),
                'left_arm_angle': frame_data.get('left_arm_angle', 0),
                'right_arm_angle': frame_data.get('right_arm_angle', 0)
            }
        }
        self.json_log.append(json_data)
        
        if len(self.json_log) % 30 == 0:
            with open(self.json_path, 'w') as f:
                json.dump(self.json_log, f, indent=2)

    def export_csv_for_sheets(self):
        csv_filename = "viewer_metrics_for_sheets.csv"
        try:
            with open(csv_filename, 'w', newline='') as f:
                writer = csv.writer(f)
                writer.writerow(['Timestamp', 'Eye Openness', 'Blink Rate', 'Mouth Openness', 
                           'Mouth Movement', 'Head Movement', 'Eye Movement X', 'Eye Movement Y',
                           'Shoulder Movement', 'Arm Movement', 'Body Rotation', 
                           'Left Arm Angle', 'Right Arm Angle'])
            
                for entry in self.json_log:
                    writer.writerow([
                        entry['timestamp'],
                        entry['metrics']['eye_openness'],
                        entry['metrics']['blink_rate'],
                        entry['metrics']['mouth_openness'],
                        entry['metrics']['mouth_movement'],
                        entry['metrics']['head_movement'],
                        entry['metrics']['eye_movement_x'],
                        entry['metrics']['eye_movement_y'],
                        entry['metrics'].get('shoulder_movement', 0),
                        entry['metrics'].get('arm_movement', 0),
                        entry['metrics'].get('upper_body_rotation', 0),
                        entry['metrics'].get('left_arm_angle', 0),
                        entry['metrics'].get('right_arm_angle', 0)
                    ])
            print(f"Data exported to {csv_filename}")
        except Exception as e:
            print(f"Error exporting CSV: {e}")

    def __del__(self):
        if hasattr(self, 'cap'):
            self.cap.release()
        if hasattr(self, 'json_log'):
            with open(self.json_path, 'w') as f:
                json.dump(self.json_log, f, indent=2)
            self.export_csv_for_sheets()

def main():
    try:
        analyzer = ViewerAnalysis()
        while True:
            annotated_frame = analyzer.process_frame(show=True)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
            time.sleep(0.01)
    except Exception as e:
        print(f"Error in main loop: {e}")
    finally:
        analyzer.export_csv_for_sheets()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    main()